{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Performance_metrics_Instructions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Ej_bXyQvnV"
      },
      "source": [
        "# Compute performance metrics for the given Y and Y_score without sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CHb6NE7Qvnc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# other than these two you should not import any other packages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbsWXuDaQvnq"
      },
      "source": [
        "<pre>\n",
        "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
        "   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
        "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> Compute Confusion Matrix </li>\n",
        "<li> Compute F1 Score </li>\n",
        "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaFLW7oBQvnt"
      },
      "source": [
        "# Function definitions required for A and B\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "#calculate predicted y by using probabilty value\n",
        "def predicted_y(data,threshold=0.5):\n",
        "  pred_y = data['proba']\n",
        "  pred_y = np.where(pred_y >= threshold, 1, 0)\n",
        "  return pred_y\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "# 1. Confusion Matrix\n",
        "# here we will calculate 4 terms : TP , TN, FP, FN\n",
        "\n",
        "# TP = No of points of positive class(1) which are predicted correctly as class 1\n",
        "# TN = No of points of negative class(0) which are predicted correctly as class 0\n",
        "# FP = No of points of negative class(0) which are predicted incorrectly as class 1\n",
        "# FN = No of points of positive class(1) which are predicted incorrectly as class 0\n",
        "\n",
        "def Confusion_Matrix(data):\n",
        "  \n",
        "  TP_pts = np.where((data['y'] == data['pred_y']) & (data['y'] == 1))\n",
        "  TP=len(TP_pts[0])\n",
        "\n",
        "  TN_pts = np.where((data['y'] == data['pred_y']) & (data['y'] == 0))\n",
        "  TN=len(TN_pts[0])\n",
        "\n",
        "  FP_pts = np.where((data['y'] != data['pred_y']) & (data['y'] == 0))\n",
        "  FP=len(FP_pts[0])\n",
        "\n",
        "  FN_pts = np.where((data['y'] != data['pred_y']) & (data['y'] == 1))\n",
        "  FN=len(FN_pts[0])\n",
        "\n",
        "  return TP,TN,FP,FN\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "# 2. F1 SCORE\n",
        "#Here we will calculate precision and recall to calculate f1 score\n",
        "#precision = TP/(TP+FP) and recall = TP/(TP+TN)\n",
        "\n",
        "def Get_F1Score(TP,TN,FP,FN):\n",
        "  precision = TP/(TP+FP)\n",
        "  recall = TP/(TP+FN)\n",
        "  F1_score = (2 *precision * recall)/(precision + recall) \n",
        "  return precision,recall,F1_score\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "# 3. AUC Score\n",
        "def ROC_AUC(data):\n",
        "\n",
        "  sorted_data = data.sort_values(by=['proba'],ascending=False)\n",
        "  threshold = list(set(sorted_data['proba']))\n",
        "\n",
        "  TPR_list = []\n",
        "  FPR_list = []\n",
        "\n",
        "  for itr in range(len(threshold)):\n",
        "    \n",
        "    new_y = predicted_y(data,threshold[itr])\n",
        "\n",
        "    data = data.assign(pred_y=new_y)\n",
        "    TP,TN,FP,FN = Confusion_Matrix(data)\n",
        "\n",
        "    TPR = TP/(TP+FN)\n",
        "    FPR = FP/(FP+TN)\n",
        "\n",
        "    TPR_list.append(TPR)\n",
        "    FPR_list.append(FPR)\n",
        "\n",
        "  FPR_list = sorted(FPR_list,reverse=False)\n",
        "  TPR_list = sorted(TPR_list,reverse=False)\n",
        "\n",
        "  AUC = np.trapz(TPR_list, FPR_list)\n",
        "  return AUC,FPR_list,TPR_list\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "# 4. Accuracy\n",
        "def Accuracy(TP,TN,FP,FN):\n",
        "  acc = (TP+TN)/(TP+TN+FP+FN)\n",
        "  return acc\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaLSJ5peoO7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "99d9f8d2-eee0-4591-f7e1-bd14b1f6bae2"
      },
      "source": [
        "#A -\n",
        "\n",
        "data_a = pd.read_csv(\"5_a.csv\")\n",
        "\n",
        "#predictiong y by its p_scores\n",
        "pred_y = predicted_y(data_a)\n",
        "data_a['pred_y'] = pred_y\n",
        "\n",
        "#1. Confusion Matrix\n",
        "TP,TN,FP,FN = Confusion_Matrix(data_a)\n",
        "print(\"TP : \",TP)\n",
        "print(\"TN : \",TN)\n",
        "print(\"FP : \",FP)\n",
        "print(\"FN : \",FN)\n",
        "\n",
        "#2. F1 Score\n",
        "precision,recall,F1_score = Get_F1Score(TP,TN,FP,FN)\n",
        "print(\"\\nPrecision : \",precision)\n",
        "print(\"Recall : \",recall)\n",
        "print(\"F1 Score : \",F1_score)\n",
        "\n",
        "#3. AUC\n",
        "AUC,FPR,TPR = ROC_AUC(data_a)\n",
        "print(\"\\nAUC : \",AUC)\n",
        "\n",
        "#4. Accuracy\n",
        "print(\"\\nAccuracy : \",Accuracy(TP,TN,FP,FN))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP :  10000\n",
            "TN :  0\n",
            "FP :  100\n",
            "FN :  0\n",
            "\n",
            "Precision :  0.9900990099009901\n",
            "Recall :  1.0\n",
            "F1 Score :  0.9950248756218906\n",
            "\n",
            "AUC :  0.48829900000000004\n",
            "\n",
            "Accuracy :  0.9900990099009901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5KZem1BQvn2"
      },
      "source": [
        "<pre>\n",
        "<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n",
        "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
        "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> Compute Confusion Matrix </li>\n",
        "<li> Compute F1 Score </li>\n",
        "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sKlq0YQvn5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4d6af7bf-2e9e-4b45-f98f-385332e1fb14"
      },
      "source": [
        "#B -\n",
        "\n",
        "data_b = pd.read_csv(\"5_b.csv\")\n",
        "\n",
        "#predictiong y by its p_scores\n",
        "pred_y = predicted_y(data_b)\n",
        "data_b['pred_y'] = pred_y\n",
        "\n",
        "#1. Confusion Matrix\n",
        "TP,TN,FP,FN = Confusion_Matrix(data_b)\n",
        "print(\"TP : \",TP)\n",
        "print(\"TN : \",TN)\n",
        "print(\"FP : \",FP)\n",
        "print(\"FN : \",FN)\n",
        "\n",
        "#2. F1 Score\n",
        "precision,recall,F1_score = Get_F1Score(TP,TN,FP,FN)\n",
        "print(\"\\nPrecision : \",precision)\n",
        "print(\"Recall : \",recall)\n",
        "print(\"F1 Score : \",F1_score)\n",
        "\n",
        "#3. AUC\n",
        "AUC,FPR,TPR = ROC_AUC(data_b)\n",
        "print(\"\\nAUC : \",AUC)\n",
        "\n",
        "#4. Accuracy\n",
        "print(\"\\nAccuracy : \",Accuracy(TP,TN,FP,FN))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP :  55\n",
            "TN :  9761\n",
            "FP :  239\n",
            "FN :  45\n",
            "\n",
            "Precision :  0.1870748299319728\n",
            "Recall :  0.55\n",
            "F1 Score :  0.2791878172588833\n",
            "\n",
            "AUC :  0.9377570000000001\n",
            "\n",
            "Accuracy :  0.9718811881188119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiPGonTzQvoB"
      },
      "source": [
        "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
        "<br>\n",
        "\n",
        "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
        "\n",
        "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
        "\n",
        "<pre>\n",
        "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5HIJzq1QvoE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0f459843-134b-45c9-c206-23773958ba26"
      },
      "source": [
        "#C -\n",
        "\n",
        "data_c = pd.read_csv(\"5_c.csv\")\n",
        "\n",
        "#could not use already defined function due to difference in column names in files - proba and prob\n",
        "def predicted_y(data,threshold=0.5):\n",
        "  pred_y = data['prob']\n",
        "  pred_y = np.where(pred_y >= threshold, 1, 0)\n",
        "  return pred_y\n",
        "\n",
        "#get the best threshold value from all the unique thresholds\n",
        "def get_Threshold(data):\n",
        "  \n",
        "  sorted_data = data.sort_values(by=['prob'],ascending=False)\n",
        "  threshold = list(set(sorted_data['prob']))\n",
        "\n",
        "  A = {}\n",
        "\n",
        "  for itr in range(len(threshold)):\n",
        "    new_y = predicted_y(data,threshold[itr])\n",
        "\n",
        "    data['pred_y'] = new_y\n",
        "    TP,TN,FP,FN = Confusion_Matrix(data)\n",
        "    \n",
        "    A_VAL = (500 * FN) + (100 * FP)\n",
        "    A[threshold[itr]]=A_VAL\n",
        "\n",
        "  #getting min of A and corresponding threshold value  \n",
        "  Best_Threshold =  [key for key in A if all(A[temp] >= A[key] for temp in A)]\n",
        "\n",
        "  return Best_Threshold[0]\n",
        "\n",
        "\n",
        "#get best threashold\n",
        "Best_Threshold = get_Threshold(data_c)\n",
        "print(\"Best Threshold : \",Best_Threshold)\n",
        "\n",
        "#predict y by using that best threshold\n",
        "pred_y = predicted_y(data_c,Best_Threshold)\n",
        "data_c['pred_y'] = pred_y\n",
        "\n",
        "#calc perfomance metrics for the new predicted values\n",
        "TP,TN,FP,FN = Confusion_Matrix(data_c)\n",
        "print(\"TP : \",TP)\n",
        "print(\"TN : \",TN)\n",
        "print(\"FP : \",FP)\n",
        "print(\"FN : \",FN)\n",
        "\n",
        "precision,recall,F1_score = Get_F1Score(TP,TN,FP,FN)\n",
        "print(\"\\nPrecision : \",precision)\n",
        "print(\"Recall : \",recall)\n",
        "print(\"F1 Score : \",F1_score)\n",
        "\n",
        "print(\"Accuracy : \",Accuracy(TP,TN,FP,FN))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold :  0.2300390278970873\n",
            "TP :  969\n",
            "TN :  785\n",
            "FP :  1020\n",
            "FN :  78\n",
            "\n",
            "Precision :  0.48717948717948717\n",
            "Recall :  0.9255014326647565\n",
            "F1 Score :  0.6383399209486166\n",
            "Accuracy :  0.615007012622721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD4CcgjXQvoL"
      },
      "source": [
        "<pre>\n",
        "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
        "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
        "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
        "<ol>\n",
        "<li> Compute Mean Square Error </li>\n",
        "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
        "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jhPXi4gTdIe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9269206f-74bb-4f82-cc35-e99218a4080e"
      },
      "source": [
        "#D -\n",
        "\n",
        "\n",
        "# D - 1. MEAN SQUARE ERROR\n",
        "data_d = pd.read_csv(\"5_d.csv\")\n",
        "def mean_sqaure_error(data):\n",
        "  summ = 0\n",
        "  for i in range(len(data)):\n",
        "    error = data['y'][i]-data['pred'][i]\n",
        "    err_sq = error*error\n",
        "    summ += err_sq\n",
        "  \n",
        "  res = summ/len(data)\n",
        "  return res\n",
        "\n",
        "mse = mean_sqaure_error(data_d)\n",
        "print(\"Mean Sqaure Error : \",mse)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Sqaure Error :  177.16569974554707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGCFMhGDVYVl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1400bb8-2802-465d-dec7-239f334ef1ad"
      },
      "source": [
        "# D - 2. MEAN ABSOLUTE PERCENTAGE ERROR\n",
        "def get_MAPE(data):\n",
        "  err_sum = 0\n",
        "  actuals = 0\n",
        "\n",
        "  for i in range(len(data)):\n",
        "    err_sum += abs(data['y'][i]-data['pred'][i])\n",
        "    actuals += data['y'][i]\n",
        "  \n",
        "  MAPE = err_sum/actuals\n",
        "  return MAPE*100\n",
        "\n",
        "MAPE = get_MAPE(data_d)\n",
        "print(\"MAPE : \",MAPE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE :  12.91202994009687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_aX7TaecoiA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "708812d4-90ea-47db-cb60-f23566547767"
      },
      "source": [
        "# D - 3. R^2 ERROR\n",
        "def R_sq_error(data):\n",
        "  #step 1 - calc mean of y_actuals\n",
        "  y_mean = np.mean(data['y'])\n",
        "  print(\"Mean of Y: \",y_mean)\n",
        "\n",
        "  #step 2 - calc SStotal\n",
        "  SS_t = 0\n",
        "  for i in range(len(data)):\n",
        "    SS_t += ((data['y'][i]-y_mean) * (data['y'][i]-y_mean))\n",
        "  print(\"SStotal: \",SS_t)\n",
        "\n",
        "  #step 3 - calc SSres\n",
        "  SS_r = 0\n",
        "  for i in range(len(data)):\n",
        "    err = (data['y'][i]-data['pred'][i])\n",
        "    SS_r += err*err\n",
        "  print(\"SSres : \",SS_r)\n",
        "\n",
        "  #step 4 - cal R^2 error\n",
        "  R_sq = 1 - (SS_r/SS_t)\n",
        "  print(\"R Sqaure Error: \",R_sq)\n",
        "\n",
        "R_sq_error(data_d)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Y:  66.56208651399491\n",
            "SStotal:  638161080.035662\n",
            "SSres :  27850448.0\n",
            "R Sqaure Error:  0.9563582786990964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5KmXGVEkZVu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}